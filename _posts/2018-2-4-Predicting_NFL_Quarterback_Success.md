---
layout: post
title: Predicting NFL Quarterback Success
comments: true
---

# Predicting Quarterbacks
Last week I finished my second project for Metis, building a model that would predict NFL quarterback success out of college. To do this, I scraped data on college and NFL quarterbacks from [Sports-Reference.com](https://www.sports-reference.com). By combining the NFL and CFB data, I was able to look at a college quarterback's statistics and then see how they performed in the NFL. I measured each quarterback's performance as his [passer rating](https://en.wikipedia.org/wiki/Passer_rating) in his first true season, which is an aggregate statistic developed by the NFL to assess passing performance. I also was able to include some "biographic" statistics, such as which arm they threw with, their college, hometown, etc.

Because NFL teams are constantly trying to avoid the [Johnny Manziels](https://en.wikipedia.org/wiki/Johnny_Manziel) of the world and get great deals on the [Tom Bradys](https://en.wikipedia.org/wiki/Tom_Brady), I had hoped my model would be able to predict the outlying quarterbacks. Most quarterbacks who end up playing in the NFL hit a minimum bar of skill, so some of the model is self-selecting - bad college quarterbacks aren't even going to be included in the dataset. This being said, most of the quarterbacks in the NFL have average passer ratings - the key is being able to predict those who are outside the norm.

Unfortunately, my model did an exceptionally poor job at doing this - with the input variables I was looking at, it predicted each quarterback as very average (in the range of 50-70 QBR). In the graph below, you can see that trend. Almost every predicted point is in the middle of the graph while great (and terrible!) quarterbacks clearly exist in the dataset.

<img src="/images/Luther_Model.png" alt="Luther" style="width: 600px;"/>

Since this is a question that has been asked many times by NFL teams, scouts, and fans, I thought I would dive into the internet to see what others had done and if any of them were able to do better than my model.


### Regression
At [The Daily Norseman](https://www.dailynorseman.com/2014/7/19/5918071/from-boom-to-bust-building-a-predictive-quarterback-model), the "CCNorseman" and Brad Davis put together a model to predict which quarterback the Minnesota Vikings should take as their 2014 first-round draft pick. For their model, "Adjusted Net Yards per Attempt" (ANY/A) was used as the response -  they claim that "as many know, ANY/A is the QB efficiency statistic that most closely correlates with winning in the NFL." For features, NFL scouting data was used, but the source and the specific features are left unclear. 

Davis used a linear model in conjunction with elastic net regularization as I did and ended up with an R<sup>2</sup> value of .3, which is reasonably good for such a difficult to predict dataset. He also used attempted to use a random forest, but ended up with a fairly similar R<sup>2</sup>. Since the blog is a bit old, we actually get to look into their original predictions a bit - players like [Teddy Bridgewater](https://en.wikipedia.org/wiki/Teddy_Bridgewater) and [Jimmy Garoppolo](https://en.wikipedia.org/wiki/Jimmy_Garoppolo) were predicted to do well and players like Johnny Manziel and [AJ McCarron](https://en.wikipedia.org/wiki/AJ_McCarron#2017_season) (Roll Tide!) were predicted to fare poorly. They do note that the difference between their #1 and #2 predictions was about the same as the difference between the 2<sup>nd</sup> and 6<sup>th</sup> ranked player, which indicates Bridgewater was a head above the rest. As we known, Manziel turned out to be a bust, as did AJ McCarron (draft pick 164). Bridgewater (pick 32) was a strong starter for the Vikings but was injured in 2016 and has had limited playtime since. Jimmy Garoppoli (pick 62) spent the last 3 years backing up Tom Brady, so hasn't seen much playing time. Obviously it's a small and anecdotal dataset, but Davis' ability to pick Manziel as a bust was a good result!

On the [Harvard Sports Analytics Collective Blog](http://harvardsportsanalysis.org/2015/02/the-combine-actually-matters-part-2/), Bill Lotter outlines a model he developed for all positions, using the player's percentile rank of "3 Year Approximate Value" (3YAV), which is a 3-year aggregate measurement of [approximate value](https://www.pro-football-reference.com/blog/index2905.html?p=466) (AV). AV is a metric developed by Doug Drinen, the founder of [PFR](https://www.pro-football-reference.com) that aims to calculate the value of a player. A numbers of models I saw used AV to identify success and it seems to be fairly well regarded. Unfortunately, it's calculation is relatively complex and feels a little "back of the napkin," but delving into it would be a whole different post. For his features, he is using NFL combine data but leaves the source vague.

Lotter performed a linear regression with ridge regularization and plotted some of the most important features. Height, weight, and vertical all show strong effects in the positive direction, while forty, shuttle, and 3-cone are strong predictors in the negative direction (which makes sense - if you're faster, your times in these events go down). Because he is ranking players into percentiles, Lotter used [Spearman's rank correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) and showed that relative to other positions quarterbacks were one of the harder positions in which to predict success. I was left a bit disappointed by this analysis - there wasn't much in the way of actually predicting any player results. In [Part 3](http://harvardsportsanalysis.org/2015/02/the-combine-actually-matters-part-3-predicting-the-draft/) of his blog, Lotter goes forward in predicting the draft, but that obviously is a bit different than the response in my model.

### Classification 
I also came across a number of classification models, which in hindsight may have been a bit more intuitive. One of the most well explained models touted very strong results on Adam McCann's [blog](http://duelingdata.blogspot.com/2017/04/predicting-qb-success-in-nfl.html) and associated [paper](https://drive.google.com/file/d/0B7xv5XOVMuVzbXVJREhtSXQzU0E/view). The response in this model was either "success" or "bust", which were engineered based on a player's approximate value and NFL starts per season. The upside of this is that the model considers the player's entire career as opposed to just their first starting season. In this model, only 13% of quarterbacks were considered successful, which to me was not inherently logical, but as a tool to predict outliers actually makes some sense. I do wish the model had included a "middle of the road" category. To me, that is just as important as identifying a successful/bust quarterback.

McCann's model uses a similar set of features as mine, but included NFL combine performance. This is interesting, as I know that many players do not participate in the combine or participate in limited events - I am curious how he handled missing values for this data. In addition, McCann also included data from NFL scouting reports using [tokenization](http://blog.kaggle.com/2017/08/25/data-science-101-getting-started-in-nlp-tokenization-tutorial/) and a weighting system. I'd like to understand a bit more about these weights, as they could result in fairly different scores, but seem to be skimmed over in the paper.

McCann used a decision tree with a max depth of 4 to predict a quarterback's success that used four features for prediction: Win Percent, College Games per Season, Age, and BMI. Interestingly, some of the more complex features he developed were not factored into the model. The interpretability and simplicity of the model is great, but I would argue that his results still don't do a great job of predicting outliers. Tom Brady and [Russell Wilson](https://en.wikipedia.org/wiki/Russell_Wilson) (draft picks 199 and 75), were both predicted as busts, and Johnny Manziel (pick 22) was predicted as a success. For his examples of correctly picked quarterbacks he used [Cam Newton](https://en.wikipedia.org/wiki/Cam_Newton) and [Aaron Rodgers](https://en.wikipedia.org/wiki/Aaron_Rodgers), draft picks 1 and 24. As mentioned above, NFL needs help predicting the bargains and busts, not the more obviously good quarterbacks. Perhaps the "obvious" picks are only obvious in hindsight or the NFL scouts are just good at their jobs already, but I wonder if a more complicated classification model such as a random forest might pick up some of this from the scouting reports.

### Conclusion
In the end, I think this problem remains difficult to solve - NFL scouts and teams are still making mistakes! I do think these types of analyses will slowly get us closer to finding what makes a great NFL quarterback, although I'm sure there is still some "luck" involved. I'd love to see an analysis that delves deeper into scouting reports, news articles, or some sort of personality test. I think it is clear that playersâ€™ actions off the field have a big effect on on-field performance.

In addition, I'd love to look at an analysis of players who are drafted onto lower-tier teams. Because the worst teams in the NFL get the highest draft picks, there might be a sort of self-fulfilling prophecy where highly rated quarterbacks end up failing. If Tom Brady doesn't end up getting to play for [Bill Belichick](https://en.wikipedia.org/wiki/Bill_Belichick) and the Patriots, does he still become Tom Brady? If Johnny Manziel goes to play for Pittsburgh, does he become a hall of famer? I'm not sure how you'd even go about this analysis - you'd have to look at some alternate realities. Maybe a [synthetic control method](https://economics.mit.edu/files/11859)?